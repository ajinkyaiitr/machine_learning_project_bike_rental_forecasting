Objective

The objective of the project is - using historical usage patterns and weather data, forecast(predict) bike rental demand (number of bike users (‘cnt’)) on hourly basis.
Use the provided “Bikes Rental” data set to predict the bike demand (bike users count - 'cnt') using various best possible models (ML algorithms). Also, report the model that performs best, fine-tune the same model using one of the model fine-tuning techniques, and report the best possible combination of hyperparameters for the selected model. Lastly, use the selected model to make final predictions and compare the predicted values with the actual values.
Below are the details of the features list for the given Bikes data set:
instant: record index
dteday : date
season: season (1: springer, 2: summer, 3: fall, 4: winter)
yr: year (0: 2011, 1:2012)
mnth: month (1 to 12)
hr: hour (0 to 23)
holiday: whether the day is a holiday or not
weekday: day of the week
workingday: if day is neither weekend nor holiday is 1, otherwise is 0.
weathersit:
1: Clear, Few clouds, Partly cloudy, Partly cloudy
2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist
3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds
4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog
temp: Normalized temperature in Celsius. The values are derived via (tt_min)/(t_maxt_min), t_min=*8, t_max=+39 (only in hourly scale)
atemp: Normalized feeling temperature in Celsius. The values are derived via (tt_min)/(t_maxt_min), t_min=*16, t_max=+50 (only in hourly scale)
hum: Normalized humidity. The values are divided to 100 (max)
windspeed: Normalized wind speed. The values are divided to 67 (max)
casual: count of casual users
registered: count of registered users
cnt: count of total rental bikes including both casual and registered users

The "target" data set ('y') should have only one 'label' i.e. 'cnt'.
We will be following the below steps to solve this problem:
Importing the libraries
Using some pre-defined utility functions
Loading the data
Cleaning the data
Dividing the dataset into training and test dataset
using train_test_split in the ratio 70:30
Training several models and analyzing their performance to select a model
Fine-tuning the model by finding the best hyper-parameters and features
Evaluating selected model using test dataset


Acknowledgements

Cloudxlab is using this “Bike Sharing Demand” problem for its machine learning learners for learning and practicing. This dataset was provided by Hadi Fanaee Tork using data from Capital Bikeshare. We also thank the UCI machine learning repository for hosting the dataset.
Fanaee-T, Hadi, and Gama, Joao, Event labeling combining ensemble detectors and background knowledge, Progress in Artificial Intelligence (2013): pp. 1-15, Springer Berlin Heidelberg.






Please import the required libraries as mentioned below:

Import numpy as np
Import pandas as pd
From sklearn import preprocessing
Please import StandardScaler from Scikit Learn - preprocessing
Please import mean_squared_error from Scikit Learn - metrics
Please import linear_model from Scikit Learn
Please import matplotlib's pyplot as plt
Import os
set random seed as follows:

###################################

import numpy as np
import pandas as pd
from sklearn import preprocessing
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error
from sklearn import linear_model
import matplotlib.pyplot as plt
import os
np.random.seed(42)
###################################


-----------------------
Loading the data
-----------------------

Loading the data
Loading the data

To start with, let us load the "Bikes Rental" data set (bikes.csv) and get a first hand look into the same.

The dataset contains the following parameters:

instant: record index

dteday: date

season: season (1: springer, 2: summer, 3: fall, 4: winter)

yr: year (0: 2011, 1:2012)

mnth: month (1 to 12)

hr: hour (0 to 23)

holiday: whether day is holiday or not

weekday: day of the week

workingday: if day is neither weekend nor holiday is 1, otherwise is 0.

weathersit:

1: Clear, Few clouds, Partly cloudy, Partly cloudy

2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist

3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds

4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog

temp: Normalized temperature in Celsius.

atemp: Normalized feeling temperature in Celsius.

hum: Normalized humidity. The values are divided to 100 (max)

windspeed: Normalized wind speed. The values are divided to 67 (max)

casual: count of casual users

registered: count of registered users
cnt: count of total rental bikes including both casual and registered


########################3Please follow the below steps:

Define a variable filePath to store the location path for our dataset file bikes.csv as a string. bikes.csv is located at /cxldata/datasets/project/bikes.csv. This file location is on the Linux box - web console
Use pandas library function read_csv to load this bikes.csv file using the location path defined by filePath variable above and store the loaded file into a dataframe called bikesData.
Have a look at the metadata of this bikesData dataframe by calling an appropriate function of dataframe.

##########################################3

-------------------------------
filePath = '/cxldata/datasets/project/bikes.csv'
bikesData = pd.read_csv(filePath)
print(bikesData.info())
-------------------------------


--->You can select a column from the dataset using the following syntax. This returns a Series object: dataset['column_name']

The Series object has a unique() function to find unique values. Also, try using the autocomplete feature of Jupyter or help() or dir() function to find out the values functions available on an object.

How many unique values are there in yr column of bikesData ?
bikesData['yr'].value_counts()

